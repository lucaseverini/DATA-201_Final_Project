{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2fe8241-ac1a-469f-9d90-4925c81604b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully\n",
      "Python pandas version: 2.2.3\n",
      "Data directory: /Users/lseverini/Library/CloudStorage/Dropbox/SJSU/ Classes/DATA 201-21/Final Project/data\n"
     ]
    }
   ],
   "source": [
    "# Import standard libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "import datetime\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import re\n",
    "from typing import Dict, List, Tuple, Optional, Any\n",
    "\n",
    "# For database connection\n",
    "from data201 import db_connection\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler('premier_league_import.log'),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Define paths\n",
    "DATA_DIR = Path('./data')\n",
    "PROCESSED_DIR = Path('./processed')\n",
    "ERROR_DIR = Path('./error')\n",
    "\n",
    "# Create directories if they don't exist\n",
    "for directory in [DATA_DIR, PROCESSED_DIR, ERROR_DIR]:\n",
    "    directory.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"Libraries imported successfully\")\n",
    "print(f\"Python pandas version: {pd.__version__}\")\n",
    "print(f\"Data directory: {DATA_DIR.absolute()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "476f4fd1-0c0d-4f36-b6c0-620929838229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to database. Server version: 9.2.0\n",
      "All required tables exist. Ready to import data.\n"
     ]
    }
   ],
   "source": [
    "# Establish database connection\n",
    "try:\n",
    "    # Connect to the database using db_connection\n",
    "    conn = db_connection(config_file='premier_league_analytics.ini')\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    # Test connection with a simple query\n",
    "    cursor.execute(\"SELECT VERSION()\")\n",
    "    db_version = cursor.fetchone()[0]\n",
    "    print(f\"Connected to database. Server version: {db_version}\")\n",
    "    \n",
    "    # Check if required tables exist\n",
    "    cursor.execute(\"\"\"\n",
    "    SELECT COUNT(*) \n",
    "    FROM INFORMATION_SCHEMA.TABLES \n",
    "    WHERE TABLE_SCHEMA = DATABASE() \n",
    "    AND TABLE_NAME IN ('Teams', 'Matches', 'Seasons', 'stg_premier_league_raw')\n",
    "    \"\"\")\n",
    "    \n",
    "    tables_count = cursor.fetchone()[0]\n",
    "    if tables_count < 4:\n",
    "        print(\"WARNING: Some required tables don't exist. Make sure to run the database setup notebook first.\")\n",
    "    else:\n",
    "        print(\"All required tables exist. Ready to import data.\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error connecting to database: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "586711dc-a128-4d86-804c-16c94dab54a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def register_file_for_processing(filename: str, filepath: str) -> int:\n",
    "    \"\"\"\n",
    "    Register a file in the ETLLog table and return its ID.\n",
    "    \n",
    "    Args:\n",
    "        filename: Name of the file\n",
    "        filepath: Full path to the file\n",
    "        \n",
    "    Returns:\n",
    "        log_id: ID of the ETL log record\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create a new ETL log entry for this file\n",
    "        process_name = f\"Import_{filename}\"\n",
    "        \n",
    "        cursor.execute(\n",
    "            \"\"\"\n",
    "            INSERT INTO `ETLLog` (`ProcessName`, `StartTime`, `Status`)\n",
    "            VALUES (%s, NOW(), 'Pending')\n",
    "            \"\"\",\n",
    "            (process_name,)\n",
    "        )\n",
    "        log_id = cursor.lastrowid\n",
    "        conn.commit()\n",
    "        logger.info(f\"Registered file for processing: {filename}, LogID: {log_id}\")\n",
    "        return log_id\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error registering file {filename}: {e}\")\n",
    "        if 'conn' in locals():\n",
    "            conn.rollback()\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7847808a-4a17-44e8-99e8-3a77052b87c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_file_status(log_id: int, status: str, records_processed: int = 0, \n",
    "                      records_failed: int = 0, error_message: Optional[str] = None) -> bool:\n",
    "    \"\"\"\n",
    "    Update the status of an ETL process in the ETLLog table.\n",
    "    \n",
    "    Args:\n",
    "        log_id: ID of the ETL log record\n",
    "        status: New status ('Running', 'Completed', 'Failed')\n",
    "        records_processed: Number of records successfully processed\n",
    "        records_failed: Number of records that failed processing\n",
    "        error_message: Error message if processing failed\n",
    "        \n",
    "    Returns:\n",
    "        success: True if the update was successful, False otherwise\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if status == 'Running':\n",
    "            # Update status to Running\n",
    "            cursor.execute(\n",
    "                \"\"\"\n",
    "                UPDATE `ETLLog` \n",
    "                SET `Status` = %s\n",
    "                WHERE `LogID` = %s\n",
    "                \"\"\",\n",
    "                (status, log_id)\n",
    "            )\n",
    "        else:\n",
    "            # Update status to Completed or Failed with stats\n",
    "            cursor.execute(\n",
    "                \"\"\"\n",
    "                UPDATE `ETLLog` \n",
    "                SET `Status` = %s, \n",
    "                    `EndTime` = NOW(), \n",
    "                    `RecordsProcessed` = %s,\n",
    "                    `RecordsFailed` = %s,\n",
    "                    `ErrorMessage` = %s\n",
    "                WHERE `LogID` = %s\n",
    "                \"\"\",\n",
    "                (status, records_processed, records_failed, error_message, log_id)\n",
    "            )\n",
    "        \n",
    "        conn.commit()\n",
    "        logger.info(f\"Updated ETL status to {status} for LogID: {log_id}\")\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error updating ETL status: {e}\")\n",
    "        if 'conn' in locals():\n",
    "            conn.rollback()\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ace0007-fed8-4f13-908e-5b0eb94302cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_season_from_filename(filename: str) -> str:\n",
    "    \"\"\"\n",
    "    Extract the season from the filename pattern.\n",
    "    \n",
    "    Args:\n",
    "        filename: Name of the file\n",
    "        \n",
    "    Returns:\n",
    "        season: Season name in format '2023-24'\n",
    "    \"\"\"\n",
    "    # Try pattern with dash (e.g., 2023-24)\n",
    "    dash_pattern = r'(\\d{4}-\\d{2})'\n",
    "    dash_match = re.search(dash_pattern, filename)\n",
    "    if dash_match:\n",
    "        return dash_match.group(1)\n",
    "    \n",
    "    # Try pattern with underscore (e.g., 2023_2024)\n",
    "    under_pattern = r'(\\d{4}_\\d{4})'\n",
    "    under_match = re.search(under_pattern, filename)\n",
    "    if under_match:\n",
    "        year_str = under_match.group(1)\n",
    "        # Convert 2023_2024 to 2023-24\n",
    "        years = year_str.split('_')\n",
    "        return f\"{years[0]}-{years[1][2:4]}\"\n",
    "    \n",
    "    # If we can extract a four-digit year, assume current season\n",
    "    year_pattern = r'(\\d{4})'\n",
    "    year_match = re.search(year_pattern, filename)\n",
    "    if year_match:\n",
    "        year = int(year_match.group(1))\n",
    "        # If this looks like a valid recent year\n",
    "        if 2000 <= year <= 2100:\n",
    "            return f\"{year}-{str(year+1)[2:4]}\"\n",
    "    \n",
    "    # Fall back to the current season if we can't determine it\n",
    "    current_year = datetime.datetime.now().year\n",
    "    next_year = str(current_year + 1)[2:4]  # Get last two digits\n",
    "    return f\"{current_year}-{next_year}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a8b4267-13a5-4a4b-8bd2-5ba901a697da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv_to_staging(file_path: str) -> Tuple[int, int, int]:\n",
    "    \"\"\"\n",
    "    Load a CSV file into the staging table.\n",
    "    \n",
    "    Args:\n",
    "        file_path: Path to the CSV file\n",
    "        \n",
    "    Returns:\n",
    "        rows_read: Number of rows read from the file\n",
    "        rows_processed: Number of rows successfully processed\n",
    "        rows_failed: Number of rows that failed processing\n",
    "    \"\"\"\n",
    "    file_name = os.path.basename(file_path)\n",
    "    rows_read = 0\n",
    "    rows_processed = 0\n",
    "    rows_failed = 0\n",
    "    \n",
    "    try:\n",
    "        # Register ETL process for this file\n",
    "        log_id = register_file_for_processing(file_name, str(file_path))\n",
    "        \n",
    "        # Update ETL status to Running\n",
    "        update_file_status(log_id, 'Running')\n",
    "        \n",
    "        # Extract season from filename\n",
    "        season = extract_season_from_filename(file_name)\n",
    "        print(f\"Identified season as: {season}\")\n",
    "        \n",
    "        # Read the CSV file\n",
    "        print(f\"Reading file: {file_name}\")\n",
    "        df = pd.read_csv(file_path, encoding='utf-8')\n",
    "        rows_read = len(df)\n",
    "        print(f\"Read {rows_read} rows from the file\")\n",
    "        \n",
    "        # Basic validation\n",
    "        if len(df) == 0:\n",
    "            raise ValueError(\"CSV file is empty\")\n",
    "        \n",
    "        # Check for required columns\n",
    "        required_columns = ['Div', 'Date', 'HomeTeam', 'AwayTeam', 'FTHG', 'FTAG', 'FTR']\n",
    "        missing_columns = [col for col in required_columns if col not in df.columns]\n",
    "        if missing_columns:\n",
    "            raise ValueError(f\"Missing required columns: {', '.join(missing_columns)}\")\n",
    "        \n",
    "        # Display sample of the data\n",
    "        print(\"\\nSample of CSV data:\")\n",
    "        display(df.head(3))\n",
    "        \n",
    "        # Clean and prepare data\n",
    "        print(\"\\nCleaning and preparing data...\")\n",
    "        \n",
    "        # Handle date format (attempting multiple formats)\n",
    "        if 'Date' in df.columns:\n",
    "            try:\n",
    "                df['Date'] = pd.to_datetime(df['Date'], dayfirst=True).dt.strftime('%Y-%m-%d')\n",
    "            except Exception as e:\n",
    "                print(f\"Error converting dates with dayfirst=True: {e}\")\n",
    "                try:\n",
    "                    # Try UK format (DD/MM/YY)\n",
    "                    df['Date'] = pd.to_datetime(df['Date'], format='%d/%m/%y').dt.strftime('%Y-%m-%d')\n",
    "                except Exception as e:\n",
    "                    print(f\"Error converting dates with UK format: {e}\")\n",
    "                    # Last resort - try with any format\n",
    "                    df['Date'] = pd.to_datetime(df['Date'], errors='coerce').dt.strftime('%Y-%m-%d')\n",
    "        \n",
    "        # Handle missing time\n",
    "        if 'Time' not in df.columns:\n",
    "            df['Time'] = '15:00'  # Default time\n",
    "        \n",
    "        # Add season column if not present\n",
    "        df['Season'] = season\n",
    "        \n",
    "        # Add source file information\n",
    "        df['SourceFile'] = file_name\n",
    "        \n",
    "        # Get the existing columns from the staging table\n",
    "        cursor.execute(\"DESCRIBE `stg_premier_league_raw`\")\n",
    "        valid_columns = [row[0] for row in cursor.fetchall()]\n",
    "        \n",
    "        # Show all columns that are in the CSV but not in the database\n",
    "        csv_columns = set(df.columns)\n",
    "        db_columns = set(valid_columns)\n",
    "        unknown_columns = csv_columns - db_columns\n",
    "        \n",
    "        if unknown_columns:\n",
    "            print(f\"\\nWARNING: These columns from the CSV are not in the database table: {unknown_columns}\")\n",
    "            print(\"These columns will be ignored.\")\n",
    "        \n",
    "        # Handle NaN values for numeric and string columns\n",
    "        for col in df.select_dtypes(include=['float64', 'int64']).columns:\n",
    "            if col in valid_columns:\n",
    "                df[col] = df[col].fillna(0)\n",
    "            \n",
    "        for col in df.select_dtypes(include=['object']).columns:\n",
    "            if col in valid_columns:\n",
    "                df[col] = df[col].fillna('')\n",
    "        \n",
    "        # Insert data into staging table\n",
    "        print(f\"Inserting {len(df)} rows into staging table...\")\n",
    "        successful_inserts = 0\n",
    "        failed_inserts = 0\n",
    "        \n",
    "        # Begin transaction\n",
    "        cursor.execute(\"START TRANSACTION\")\n",
    "        \n",
    "        for _, row in df.iterrows():\n",
    "            try:\n",
    "                # Prepare SQL and values - only include columns that exist in the database\n",
    "                columns = []\n",
    "                placeholders = []\n",
    "                values = []\n",
    "                \n",
    "                for col in df.columns:\n",
    "                    # Only include columns that exist in the database table\n",
    "                    if col in valid_columns and pd.notna(row[col]) and row[col] != '':\n",
    "                        columns.append(f\"`{col}`\")\n",
    "                        placeholders.append(\"%s\")\n",
    "                        values.append(str(row[col]))\n",
    "                \n",
    "                # Add ProcessedFlag if it exists in valid_columns\n",
    "                if 'ProcessedFlag' in valid_columns and 'ProcessedFlag' not in columns:\n",
    "                    columns.append(\"`ProcessedFlag`\")\n",
    "                    placeholders.append(\"%s\")\n",
    "                    values.append(0)\n",
    "                \n",
    "                # Skip if no valid columns found\n",
    "                if not columns:\n",
    "                    failed_inserts += 1\n",
    "                    continue\n",
    "                \n",
    "                # Construct SQL\n",
    "                sql = f\"\"\"\n",
    "                INSERT INTO `stg_premier_league_raw` ({', '.join(columns)})\n",
    "                VALUES ({', '.join(placeholders)})\n",
    "                \"\"\"\n",
    "                \n",
    "                # Execute SQL\n",
    "                cursor.execute(sql, values)\n",
    "                successful_inserts += 1\n",
    "                \n",
    "            except Exception as e:\n",
    "                failed_inserts += 1\n",
    "                error_msg = str(e)\n",
    "                logger.warning(f\"Error inserting row: {error_msg}\")\n",
    "                print(f\"Error inserting row: {error_msg}\")\n",
    "                \n",
    "                # Log to dead letter table\n",
    "                try:\n",
    "                    cursor.execute(\n",
    "                        \"\"\"\n",
    "                        INSERT INTO `ETLDeadLetter` (`SourceTable`, `SourceId`, `ErrorMessage`, `RawData`)\n",
    "                        VALUES (%s, %s, %s, %s)\n",
    "                        \"\"\",\n",
    "                        ('stg_premier_league_raw', None, error_msg, str(row.to_dict()))\n",
    "                    )\n",
    "                except Exception as e2:\n",
    "                    logger.error(f\"Error logging to dead letter table: {e2}\")\n",
    "        \n",
    "        # Commit transaction\n",
    "        conn.commit()\n",
    "        rows_processed = successful_inserts\n",
    "        rows_failed = failed_inserts\n",
    "        \n",
    "        # Update ETL status to Completed\n",
    "        update_file_status(\n",
    "            log_id, \n",
    "            'Completed', \n",
    "            rows_processed, \n",
    "            rows_failed\n",
    "        )\n",
    "        \n",
    "        print(f\"Successfully inserted {rows_processed} rows into staging table\")\n",
    "        print(f\"Failed to insert {rows_failed} rows\")\n",
    "        \n",
    "        # Move file to processed directory\n",
    "        processed_path = PROCESSED_DIR / file_name\n",
    "        shutil.move(str(file_path), str(processed_path))\n",
    "        print(f\"Moved file to processed directory: {processed_path}\")\n",
    "        \n",
    "        return rows_read, rows_processed, rows_failed\n",
    "        \n",
    "    except Exception as e:\n",
    "        error_msg = str(e)\n",
    "        logger.error(f\"Error loading file to staging: {error_msg}\")\n",
    "        print(f\"Error loading file to staging: {error_msg}\")\n",
    "        \n",
    "        # Update ETL status to Failed\n",
    "        if 'log_id' in locals():\n",
    "            update_file_status(\n",
    "                log_id, \n",
    "                'Failed', \n",
    "                rows_processed, \n",
    "                rows_failed, \n",
    "                error_msg\n",
    "            )\n",
    "        \n",
    "        # Rollback any open transaction\n",
    "        if 'conn' in locals():\n",
    "            conn.rollback()\n",
    "        \n",
    "        return rows_read, rows_processed, rows_failed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a330a2c6-e93c-4222-b598-e61cd279c06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv_files():\n",
    "    # Find available CSV files\n",
    "    print(f\"Loading csv files from folder: {DATA_DIR}\")\n",
    "    csv_files = list(DATA_DIR.glob('*.csv'))\n",
    "    print(f\"Found {len(csv_files)} CSV files in the data directory:\")\n",
    "    for file in csv_files:\n",
    "        print(f\"  - {file.name}\")\n",
    "\n",
    "    # Test with first file if available\n",
    "    if csv_files:\n",
    "        first_file = csv_files[0]\n",
    "        if first_file:\n",
    "            print(f\"\\nTesting import with file: {first_file}\")\n",
    "            \n",
    "            # Load the file to staging\n",
    "            rows_read, rows_processed, rows_failed = load_csv_to_staging(first_file)\n",
    "            \n",
    "            # Check results\n",
    "            print(f\"\\nImport summary:\")\n",
    "            print(f\"  - Rows read: {rows_read}\")\n",
    "            print(f\"  - Rows processed: {rows_processed}\")\n",
    "            print(f\"  - Rows failed: {rows_failed}\")\n",
    "            \n",
    "            # Verify data in staging table\n",
    "            try:\n",
    "                cursor.execute(\"\"\"\n",
    "                SELECT COUNT(*) FROM `stg_premier_league_raw` \n",
    "                WHERE `SourceFile` = %s\n",
    "                \"\"\", (first_file.name,))\n",
    "                \n",
    "                stage_count = cursor.fetchone()[0]\n",
    "                print(f\"\\nVerified {stage_count} rows in staging table from this file\")\n",
    "                \n",
    "                # Show sample from staging table - get actual columns that exist\n",
    "                cursor.execute(\"DESCRIBE `stg_premier_league_raw`\")\n",
    "                actual_columns = [row[0] for row in cursor.fetchall()]\n",
    "                \n",
    "                # Only include columns that we know exist\n",
    "                display_columns = ['Id', 'Div', 'Date', 'HomeTeam', 'AwayTeam', 'FTHG', 'FTAG', 'FTR']\n",
    "                # Filter to only include columns that actually exist in the table\n",
    "                display_columns = [col for col in display_columns if col in actual_columns]\n",
    "                \n",
    "                # Add SourceFile if it exists\n",
    "                if 'SourceFile' in actual_columns:\n",
    "                    display_columns.append('SourceFile')\n",
    "                \n",
    "                if display_columns:\n",
    "                    # Build the query with only existing columns\n",
    "                    columns_sql = ', '.join([f'`{col}`' for col in display_columns])\n",
    "                    query = f\"\"\"\n",
    "                    SELECT {columns_sql}\n",
    "                    FROM `stg_premier_league_raw`\n",
    "                    WHERE `SourceFile` = %s\n",
    "                    LIMIT 5\n",
    "                    \"\"\"\n",
    "                    \n",
    "                    cursor.execute(query, (first_file.name,))\n",
    "                    \n",
    "                    columns = [col[0] for col in cursor.description]\n",
    "                    sample_data = cursor.fetchall()\n",
    "                    \n",
    "                    print(\"\\nSample data in staging table:\")\n",
    "                    sample_df = pd.DataFrame(sample_data, columns=columns)\n",
    "                    display(sample_df)\n",
    "                else:\n",
    "                    print(\"Could not determine which columns to display\")\n",
    "                \n",
    "                # Check if this file has been logged in ETLLog\n",
    "                cursor.execute(\"\"\"\n",
    "                SELECT `LogID`, `Status`, `RecordsProcessed`, `RecordsFailed` \n",
    "                FROM `ETLLog`\n",
    "                WHERE `ProcessName` LIKE %s\n",
    "                ORDER BY `LogID` DESC\n",
    "                LIMIT 1\n",
    "                \"\"\", (f\"Import_{first_file.name}%\",))\n",
    "                \n",
    "                log_data = cursor.fetchone()\n",
    "                if log_data:\n",
    "                    log_id, status, records_processed, records_failed = log_data\n",
    "                    print(f\"\\nETL Log: LogID={log_id}, Status={status}, Processed={records_processed}, Failed={records_failed}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error verifying data: {e}\")\n",
    "                return False\n",
    "            \n",
    "            return True\n",
    "    else:\n",
    "        print(\"No CSV files found in the data directory. Please add files to import.\")\n",
    "    \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397574c8-98eb-41d0-a36a-8e1a515d4f64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-08 17:07:38,025 - INFO - Registered file for processing: PL22-23.csv, LogID: 1\n",
      "2025-05-08 17:07:38,027 - INFO - Updated ETL status to Running for LogID: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading csv files from folder: data\n",
      "Found 1 CSV files in the data directory:\n",
      "  - PL22-23.csv\n",
      "\n",
      "Testing import with file: data/PL22-23.csv\n",
      "Identified season as: 2025-26\n",
      "Reading file: PL22-23.csv\n",
      "Read 380 rows from the file\n",
      "\n",
      "Sample of CSV data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Div</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>HomeTeam</th>\n",
       "      <th>AwayTeam</th>\n",
       "      <th>FTHG</th>\n",
       "      <th>FTAG</th>\n",
       "      <th>FTR</th>\n",
       "      <th>HTHG</th>\n",
       "      <th>HTAG</th>\n",
       "      <th>...</th>\n",
       "      <th>AvgC&lt;2.5</th>\n",
       "      <th>AHCh</th>\n",
       "      <th>B365CAHH</th>\n",
       "      <th>B365CAHA</th>\n",
       "      <th>PCAHH</th>\n",
       "      <th>PCAHA</th>\n",
       "      <th>MaxCAHH</th>\n",
       "      <th>MaxCAHA</th>\n",
       "      <th>AvgCAHH</th>\n",
       "      <th>AvgCAHA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E0</td>\n",
       "      <td>05/08/2022</td>\n",
       "      <td>20:00</td>\n",
       "      <td>Crystal Palace</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.76</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2.09</td>\n",
       "      <td>1.84</td>\n",
       "      <td>2.04</td>\n",
       "      <td>1.88</td>\n",
       "      <td>2.09</td>\n",
       "      <td>1.88</td>\n",
       "      <td>2.03</td>\n",
       "      <td>1.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E0</td>\n",
       "      <td>06/08/2022</td>\n",
       "      <td>12:30</td>\n",
       "      <td>Fulham</td>\n",
       "      <td>Liverpool</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>D</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.73</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1.90</td>\n",
       "      <td>2.03</td>\n",
       "      <td>1.91</td>\n",
       "      <td>2.02</td>\n",
       "      <td>2.01</td>\n",
       "      <td>2.06</td>\n",
       "      <td>1.89</td>\n",
       "      <td>1.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E0</td>\n",
       "      <td>06/08/2022</td>\n",
       "      <td>15:00</td>\n",
       "      <td>Bournemouth</td>\n",
       "      <td>Aston Villa</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>H</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.76</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.93</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.93</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.94</td>\n",
       "      <td>2.04</td>\n",
       "      <td>1.88</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 106 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Div        Date   Time        HomeTeam     AwayTeam  FTHG  FTAG FTR  HTHG  \\\n",
       "0  E0  05/08/2022  20:00  Crystal Palace      Arsenal     0     2   A     0   \n",
       "1  E0  06/08/2022  12:30          Fulham    Liverpool     2     2   D     1   \n",
       "2  E0  06/08/2022  15:00     Bournemouth  Aston Villa     2     0   H     1   \n",
       "\n",
       "   HTAG  ... AvgC<2.5  AHCh  B365CAHH  B365CAHA  PCAHH  PCAHA  MaxCAHH  \\\n",
       "0     1  ...     1.76  0.50      2.09      1.84   2.04   1.88     2.09   \n",
       "1     0  ...     2.73  1.75      1.90      2.03   1.91   2.02     2.01   \n",
       "2     0  ...     1.76  0.50      1.93      2.00   1.93   2.00     1.94   \n",
       "\n",
       "   MaxCAHA  AvgCAHH  AvgCAHA  \n",
       "0     1.88     2.03     1.85  \n",
       "1     2.06     1.89     1.99  \n",
       "2     2.04     1.88     2.00  \n",
       "\n",
       "[3 rows x 106 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cleaning and preparing data...\n",
      "\n",
      "WARNING: These columns from the CSV are not in the database table: {'B365CAHA', 'AvgC<2.5', 'AvgC>2.5', 'PCAHA', 'AvgCAHH', 'Avg>2.5', 'MaxC<2.5', 'Max<2.5', 'B365<2.5', 'MaxC>2.5', 'AvgCAHA', 'Season', 'B365C>2.5', 'B365CAHH', 'MaxCAHH', 'B365>2.5', 'PC>2.5', 'Avg<2.5', 'MaxCAHA', 'Max>2.5', 'P<2.5', 'P>2.5', 'PCAHH', 'PC<2.5', 'B365C<2.5', 'AHCh'}\n",
      "These columns will be ignored.\n",
      "Inserting 380 rows into staging table...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-08 17:07:38,367 - INFO - Updated ETL status to Completed for LogID: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully inserted 380 rows into staging table\n",
      "Failed to insert 0 rows\n",
      "Moved file to processed directory: processed/PL22-23.csv\n",
      "\n",
      "Import summary:\n",
      "  - Rows read: 380\n",
      "  - Rows processed: 380\n",
      "  - Rows failed: 0\n",
      "\n",
      "Verified 380 rows in staging table from this file\n",
      "\n",
      "Sample data in staging table:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Div</th>\n",
       "      <th>Date</th>\n",
       "      <th>HomeTeam</th>\n",
       "      <th>AwayTeam</th>\n",
       "      <th>FTHG</th>\n",
       "      <th>FTAG</th>\n",
       "      <th>FTR</th>\n",
       "      <th>SourceFile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>E0</td>\n",
       "      <td>2022-08-05</td>\n",
       "      <td>Crystal Palace</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>A</td>\n",
       "      <td>PL22-23.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>E0</td>\n",
       "      <td>2022-08-06</td>\n",
       "      <td>Fulham</td>\n",
       "      <td>Liverpool</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>D</td>\n",
       "      <td>PL22-23.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>E0</td>\n",
       "      <td>2022-08-06</td>\n",
       "      <td>Bournemouth</td>\n",
       "      <td>Aston Villa</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>H</td>\n",
       "      <td>PL22-23.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>E0</td>\n",
       "      <td>2022-08-06</td>\n",
       "      <td>Leeds</td>\n",
       "      <td>Wolves</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>H</td>\n",
       "      <td>PL22-23.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>E0</td>\n",
       "      <td>2022-08-06</td>\n",
       "      <td>Newcastle</td>\n",
       "      <td>Nott'm Forest</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>H</td>\n",
       "      <td>PL22-23.csv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id Div        Date        HomeTeam       AwayTeam  FTHG  FTAG FTR  \\\n",
       "0   1  E0  2022-08-05  Crystal Palace        Arsenal     0     2   A   \n",
       "1   2  E0  2022-08-06          Fulham      Liverpool     2     2   D   \n",
       "2   3  E0  2022-08-06     Bournemouth    Aston Villa     2     0   H   \n",
       "3   4  E0  2022-08-06           Leeds         Wolves     2     1   H   \n",
       "4   5  E0  2022-08-06       Newcastle  Nott'm Forest     2     0   H   \n",
       "\n",
       "    SourceFile  \n",
       "0  PL22-23.csv  \n",
       "1  PL22-23.csv  \n",
       "2  PL22-23.csv  \n",
       "3  PL22-23.csv  \n",
       "4  PL22-23.csv  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ETL Log: LogID=1, Status=Completed, Processed=380, Failed=0\n",
      "Found 380 records to process\n",
      "Transform-load completed. Processed: 380, Failed: 0\n"
     ]
    }
   ],
   "source": [
    "def transform_load_data():\n",
    "    \"\"\"Transform and load data from staging to operational tables\"\"\"\n",
    "    conn = None\n",
    "    cursor = None\n",
    "    records_processed = 0\n",
    "    records_failed = 0\n",
    "\n",
    "    try:\n",
    "        # 1) connect & fetch staging rows\n",
    "        conn = db_connection(config_file='premier_league_analytics.ini')\n",
    "        cursor = conn.cursor(dictionary=True)\n",
    "        cursor.execute(\"\"\"\n",
    "            SELECT * \n",
    "            FROM `stg_premier_league_raw`\n",
    "            WHERE `ProcessedFlag` = 0\n",
    "            ORDER BY `Id`\n",
    "        \"\"\")\n",
    "\n",
    "        staging = cursor.fetchall()\n",
    "        if not staging:\n",
    "            print(\"No unprocessed data found in staging table\")\n",
    "            return True\n",
    "        print(f\"Found {len(staging)} records to process\")\n",
    "\n",
    "        # 2) cache MarketIDs & BookmakerIDs\n",
    "        cursor.execute(\"SELECT MarketID FROM `Markets` WHERE MarketType='MatchResult'\")\n",
    "        m = cursor.fetchone()\n",
    "        match_result_mid = m['MarketID'] if m else None\n",
    "\n",
    "        cursor.execute(\"SELECT MarketID FROM `Markets` WHERE MarketType='OverUnder' AND Parameter='2.5'\")\n",
    "        m = cursor.fetchone()\n",
    "        ou_mid = m['MarketID'] if m else None\n",
    " \n",
    "        cursor.execute(\"SELECT BookmakerCode, BookmakerID FROM `Bookmakers`\")\n",
    "        bookmaker_ids = {r['BookmakerCode']: r['BookmakerID'] for r in cursor.fetchall()}\n",
    "\n",
    "        # 3) mapping for 1X2 odds columns\n",
    "        three_way = [\n",
    "            ('B365','B365H','B365D','B365A'),\n",
    "            ('BW','BWH','BWD','BWA'),\n",
    "            ('IW','IWH','IWD','IWA'),\n",
    "            ('PS','PSH','PSD','PSA'),\n",
    "            ('WH','WHH','WHD','WHA'),\n",
    "            ('VC','VCH','VCD','VCA'),\n",
    "        ]\n",
    "\n",
    "        # 4) process each row\n",
    "        for row in staging:\n",
    "            try:\n",
    "                # a) skip if essential missing\n",
    "                if not all([row.get('Div'), row.get('Date'),\n",
    "                            row.get('HomeTeam'), row.get('AwayTeam')]):\n",
    "                    print(f\"Skipping {row['Id']}: missing data\")\n",
    "                    records_failed += 1\n",
    "                    continue\n",
    "\n",
    "                # b) parse match date\n",
    "                raw = row['Date']\n",
    "                if isinstance(raw, str):\n",
    "                    md = datetime.strptime(raw, '%Y-%m-%d').date()\n",
    "                else:\n",
    "                    md = raw\n",
    "\n",
    "                # c) season logic Aug→May = XYAB\n",
    "                if md.month >= 8:\n",
    "                    sy = md.year % 100\n",
    "                    ey = (md.year + 1) % 100\n",
    "                else:\n",
    "                    sy = (md.year - 1) % 100\n",
    "                    ey = md.year % 100\n",
    "                season_name = f\"{sy:02d}-{ey:02d}\"\n",
    "\n",
    "                # d) upsert Seasons\n",
    "                cursor.execute(\n",
    "                    \"SELECT SeasonID FROM `Seasons` WHERE SeasonName=%s\",\n",
    "                    (season_name,)\n",
    "                )\n",
    "                r = cursor.fetchone()\n",
    "                if r:\n",
    "                    season_id = r['SeasonID']\n",
    "                else:\n",
    "                    # set bounds\n",
    "                    if md.month >= 8:\n",
    "                        start_dt = f\"{md.year}-08-01\"\n",
    "                        end_dt   = f\"{md.year+1}-05-31\"\n",
    "                    else:\n",
    "                        start_dt = f\"{md.year-1}-08-01\"\n",
    "                        end_dt   = f\"{md.year}-05-31\"\n",
    "                    cursor.execute(\n",
    "                        \"INSERT INTO `Seasons`(SeasonName,StartDate,EndDate) VALUES(%s,%s,%s)\",\n",
    "                        (season_name, start_dt, end_dt)\n",
    "                    )\n",
    "                    season_id = cursor.lastrowid\n",
    "\n",
    "                # e) upsert Divisions\n",
    "                div = row['Div']\n",
    "                cursor.execute(\n",
    "                    \"SELECT DivisionID FROM `Divisions` WHERE DivisionCode=%s\",\n",
    "                    (div,)\n",
    "                )\n",
    "                r = cursor.fetchone()\n",
    "                if r:\n",
    "                    div_id = r['DivisionID']\n",
    "                else:\n",
    "                    cursor.execute(\n",
    "                        \"INSERT INTO `Divisions`(DivisionCode,LeagueName) VALUES(%s,%s)\",\n",
    "                        (div, f\"{div} League\")\n",
    "                    )\n",
    "                    div_id = cursor.lastrowid\n",
    "\n",
    "                # f) upsert Teams\n",
    "                def upsert_team(name):\n",
    "                    cursor.execute(\"SELECT TeamID FROM `Teams` WHERE TeamName=%s\", (name,))\n",
    "                    rr = cursor.fetchone()\n",
    "                    if rr:\n",
    "                        return rr['TeamID']\n",
    "                    short = ''.join(w[0] for w in name.split()).upper()\n",
    "                    cursor.execute(\n",
    "                        \"INSERT INTO `Teams`(TeamName,ShortName) VALUES(%s,%s)\",\n",
    "                        (name, short)\n",
    "                    )\n",
    "                    return cursor.lastrowid\n",
    "\n",
    "                home_id = upsert_team(row['HomeTeam'])\n",
    "                away_id = upsert_team(row['AwayTeam'])\n",
    "\n",
    "                # g) upsert Referee\n",
    "                ref_id = None\n",
    "                if row.get('Referee'):\n",
    "                    ref = row['Referee'].strip()\n",
    "                    cursor.execute(\n",
    "                        \"SELECT RefereeID FROM `Referees` WHERE RefereeName=%s\",\n",
    "                        (ref,)\n",
    "                    )\n",
    "                    rr = cursor.fetchone()\n",
    "                    if rr:\n",
    "                        ref_id = rr['RefereeID']\n",
    "                    else:\n",
    "                        cursor.execute(\n",
    "                            \"INSERT INTO `Referees`(RefereeName) VALUES(%s)\",\n",
    "                            (ref,)\n",
    "                        )\n",
    "                        ref_id = cursor.lastrowid\n",
    "\n",
    "                # h) insert Matches\n",
    "                cursor.execute(\"\"\"\n",
    "                    INSERT INTO `Matches`(\n",
    "                      SeasonID,DivisionID,MatchDate,MatchTime,\n",
    "                      HomeTeamID,AwayTeamID,FTHG,FTAG,FTR,\n",
    "                      HTHG,HTAG,HTR,RefereeID\n",
    "                    ) VALUES(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s)\n",
    "                \"\"\",(\n",
    "                    season_id, div_id, md, row.get('Time'),\n",
    "                    home_id, away_id,\n",
    "                    row.get('FTHG',0), row.get('FTAG',0), row.get('FTR'),\n",
    "                    row.get('HTHG'), row.get('HTAG'), row.get('HTR'),\n",
    "                    ref_id\n",
    "                ))\n",
    "                match_id = cursor.lastrowid\n",
    "\n",
    "                # i) insert MatchStatistics\n",
    "                cursor.execute(\"\"\"\n",
    "                    INSERT INTO `MatchStatistics`(\n",
    "                      MatchID,HomeShots,AwayShots,\n",
    "                      HomeShotsTarget,AwayShotsTarget,\n",
    "                      HomeCorners,AwayCorners,\n",
    "                      HomeFouls,AwayFouls,\n",
    "                      HomeYellowCards,AwayYellowCards,\n",
    "                      HomeRedCards,AwayRedCards\n",
    "                    ) VALUES(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s)\n",
    "                \"\"\",(\n",
    "                    match_id,\n",
    "                    row.get('HS'),  row.get('AS'),\n",
    "                    row.get('HST'), row.get('AST'),\n",
    "                    row.get('HC'),  row.get('AC'),\n",
    "                    row.get('HF'),  row.get('AF'),\n",
    "                    row.get('HY'),  row.get('AY'),\n",
    "                    row.get('HR'),  row.get('AR'),\n",
    "                ))\n",
    "\n",
    "                # j) insert BettingOdds 1X2\n",
    "                if match_result_mid:\n",
    "                    for code, hcol, dcol, acol in three_way:\n",
    "                        if code in bookmaker_ids:\n",
    "                            try:\n",
    "                                h = float(row[hcol])\n",
    "                                d = float(row[dcol])\n",
    "                                a = float(row[acol])\n",
    "                            except (TypeError, ValueError):\n",
    "                                continue\n",
    "                            if h>1 and d>1 and a>1:\n",
    "                                bid = bookmaker_ids[code]\n",
    "                                for oc, val in [('H',h),('D',d),('A',a)]:\n",
    "                                    cursor.execute(\n",
    "                                        \"INSERT INTO `BettingOdds`\"\n",
    "                                        \"(MatchID,BookmakerID,MarketID,OutcomeCode,OddsValue)\"\n",
    "                                        \" VALUES(%s,%s,%s,%s,%s)\",\n",
    "                                        (match_id,bid,match_result_mid,oc,val)\n",
    "                                    )\n",
    "\n",
    "                # k) insert BettingOdds Over/Under 2.5\n",
    "                if ou_mid and 'B365' in bookmaker_ids:\n",
    "                    ocol, ucol = 'B365>2.5','B365<2.5'\n",
    "                    try:\n",
    "                        o = float(row.get(ocol,0))\n",
    "                        u = float(row.get(ucol,0))\n",
    "                    except (TypeError, ValueError):\n",
    "                        o=u=0\n",
    "                    if o>1 and u>1:\n",
    "                        bid = bookmaker_ids['B365']\n",
    "                        for oc, val in [('O',o),('U',u)]:\n",
    "                            cursor.execute(\n",
    "                                \"INSERT INTO `BettingOdds`\"\n",
    "                                \"(MatchID,BookmakerID,MarketID,OutcomeCode,OddsValue)\"\n",
    "                                \" VALUES(%s,%s,%s,%s,%s)\",\n",
    "                                (match_id,bid,ou_mid,oc,val)\n",
    "                            )\n",
    "\n",
    "                # l) mark processed\n",
    "                cursor.execute(\n",
    "                    \"UPDATE `stg_premier_league_raw` SET ProcessedFlag=1 WHERE Id=%s\",\n",
    "                    (row['Id'],)\n",
    "                )\n",
    "                conn.commit()\n",
    "                records_processed += 1\n",
    "\n",
    "            except Exception as rec_e:\n",
    "                conn.rollback()\n",
    "                print(f\"Error processing row {row['Id']}: {rec_e}\")\n",
    "                records_failed += 1\n",
    "\n",
    "        print(f\"Transform-load completed. Processed: {records_processed}, Failed: {records_failed}\")\n",
    "        return True\n",
    "\n",
    "    except Exception as e:\n",
    "        if conn:\n",
    "            conn.rollback()\n",
    "        print(f\"Fatal error in transform-load: {e}\")\n",
    "        return False\n",
    "\n",
    "    finally:\n",
    "        if cursor:\n",
    "            cursor.close()\n",
    "        if conn:\n",
    "            conn.close()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    if load_csv_files():\n",
    "        transform_load_data()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
